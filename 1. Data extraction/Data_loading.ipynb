{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cagutierrezgu/My_Portfolio/blob/main/Podcast%20topic%20classification/Data%20extraction/Data_loading.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e0157ca",
      "metadata": {
        "id": "6e0157ca"
      },
      "source": [
        "## Data loading\n",
        "\n",
        "A continuación se presenta el desarrollo de un proyecto que busca analizar conversaciones provenientes de podcasts en inglés con diferentes temáticas. Las librerías a utilizar son las siguientes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cfaf2acb",
      "metadata": {
        "id": "cfaf2acb"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np\n",
        "from os import path, getcwd, listdir\n",
        "from bs4 import BeautifulSoup\n",
        "from bs4.dammit import EncodingDetector\n",
        "from wordcloud import WordCloud\n",
        "from pprint import pprint\n",
        "\n",
        "# Preprocesamiento y limpieza de datos\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from gensim.models import Word2Vec as w2v\n",
        "\n",
        "# Modelos a implementar\n",
        "import sklearn\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_samples\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models import CoherenceModel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2fad2f0e",
      "metadata": {
        "id": "2fad2f0e"
      },
      "source": [
        "El análisis se realizará sobre texto proveniente de conversaciones de varios capítulos de diferentes podcasts en inglés. Dicho material se encuentra alojado en la web, específicamente la información a utilizar se encuentra en la página de [happyscribe](https://www.happyscribe.com/), la cual almacena podcasts de diferentes temáticas con sus respectivos guiones.\n",
        "\n",
        "En primer lugar, definimos algunas funciones para posteriormente extraer los textos a analizar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fc19cc8",
      "metadata": {
        "id": "0fc19cc8"
      },
      "outputs": [],
      "source": [
        "def get_soup(html):\n",
        "    \"\"\"Muestra toda la información de una página respectiva\"\"\"\n",
        "    resp = requests.get(html)\n",
        "    http_encoding = resp.encoding if 'charset' in resp.headers.get('content-type', '').lower() else None\n",
        "    html_encoding = EncodingDetector.find_declared_encoding(resp.content, is_html=True)\n",
        "    encoding = html_encoding or http_encoding\n",
        "    soup = BeautifulSoup(resp.content, from_encoding=encoding)\n",
        "    return soup\n",
        "\n",
        "def get_links(soup):\n",
        "    \"\"\"Extrae los links contenidos en una página web\"\"\"\n",
        "    http_link_list = [] \n",
        "    for link in soup.find_all('a', href=True):\n",
        "        http_link_list.append(link['href'].strip(\"'\"))\n",
        "    return http_link_list\n",
        "\n",
        "def get_ps(soup):\n",
        "    \"\"\"Obtiene los tags <p> de una página, que contienen el texto\"\"\"\n",
        "    http_link_list = [] \n",
        "    for link in soup.find_all('p'):\n",
        "        http_link_list.append(link.get_text())\n",
        "    return http_link_list \n",
        "\n",
        "def get_text(text_array):\n",
        "    \"\"\"Junta el texto de una página web\"\"\"\n",
        "    text = \" \".join(text_array)\n",
        "    return text\n",
        "\n",
        "def get_episode_text(episode_list):\n",
        "    \"\"\"Lista el texto de cada episodio usando otras funciones ya definidas\"\"\"\n",
        "    text_return = []\n",
        "    for i in episode_list:\n",
        "        #print(i)\n",
        "        soup = get_soup(i)\n",
        "        text_array = get_ps(soup)\n",
        "        full_text = get_text(text_array)\n",
        "        text_return.append(full_text)\n",
        "    return text_return"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "953b6031",
      "metadata": {
        "id": "953b6031"
      },
      "source": [
        "El estudio se realizará sobre 5 diferentes podcasts, cada uno de temáticas diferentes. Uno de ellos será [Lex Fridman Podcast](https://www.happyscribe.com/public/lex-fridman-podcast-artificial-intelligence-ai) catalogado como un podcast de ciencia, así que cargarán alrededor de los últimos 100 episodios disponibles en la página web:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b166e44d",
      "metadata": {
        "id": "b166e44d"
      },
      "outputs": [],
      "source": [
        "science_transcripts = ['https://www.happyscribe.com/public/lex-fridman-podcast-artificial-intelligence-ai',\n",
        "                      'https://www.happyscribe.com/public/lex-fridman-podcast-artificial-intelligence-ai?page=2',\n",
        "                      'https://www.happyscribe.com/public/lex-fridman-podcast-artificial-intelligence-ai?page=3']\n",
        "\n",
        "soup_science = list(map(get_soup, science_transcripts))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d5958a1",
      "metadata": {
        "id": "3d5958a1"
      },
      "source": [
        "Una vez con toda la información de las páginas webs donde se encuentran los episodios a analizar se procede a extraer los links que estas contengan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adc540d1",
      "metadata": {
        "id": "adc540d1"
      },
      "outputs": [],
      "source": [
        "h_links_science = list(map(get_links, soup_science))\n",
        "links_science = []\n",
        "for i in range(3):\n",
        "    links_science += h_links_science[i]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3d47460",
      "metadata": {
        "id": "e3d47460"
      },
      "source": [
        "Sin embargo, no todos los links son de interés para el proyecto, únicamente se requieren los que conducen a cada episodio del podcast, luego se filtran los deseados para el estudio:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56b962da",
      "metadata": {
        "id": "56b962da"
      },
      "outputs": [],
      "source": [
        "html_links_science = [lnk for lnk in links_science if 'ai/' in lnk]\n",
        "#html_links_science"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "388c963b",
      "metadata": {
        "id": "388c963b"
      },
      "source": [
        "Ahora, teniendo los links requeridos se observa que todos estos muestran únicamente la extensión de cada uno de los capítulos, así que se completa la dirección de cada página web para luego cargar la información:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62fef2e6",
      "metadata": {
        "id": "62fef2e6"
      },
      "outputs": [],
      "source": [
        "html_links_science = ['https://www.happyscribe.com'+i for i in html_links_science]\n",
        "#html_links_science"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "85a45b80",
      "metadata": {
        "id": "85a45b80"
      },
      "source": [
        "Una vez extraídos los links que contienen los guiones de los episodios a estudiar se carga el texto que cada uno de estos contiene, organizados en una lista cuyos elementos son cada uno de los episodios del podcast:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6d634b2",
      "metadata": {
        "id": "c6d634b2"
      },
      "outputs": [],
      "source": [
        "text_science = get_episode_text(html_links_science)\n",
        "#text_science"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0e7d0a4",
      "metadata": {
        "id": "f0e7d0a4"
      },
      "source": [
        "El procedimiento anterior es repetido para cargar el texto de los demás podcasts a estudiar. A continuación se carga uno con la temática de deportes llamado [The Dan Le Batard Show with Stugotz](https://www.happyscribe.com/public/the-dan-le-batard-show-with-stugotz):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "50810c83",
      "metadata": {
        "id": "50810c83"
      },
      "outputs": [],
      "source": [
        "sports_transcripts = ['https://www.happyscribe.com/public/the-dan-le-batard-show-with-stugotz',\n",
        "                     'https://www.happyscribe.com/public/the-dan-le-batard-show-with-stugotz?page=2',\n",
        "                     'https://www.happyscribe.com/public/the-dan-le-batard-show-with-stugotz?page=3']\n",
        "\n",
        "soup_sports = list(map(get_soup, sports_transcripts))\n",
        "\n",
        "h_links_sports = list(map(get_links, soup_sports))\n",
        "\n",
        "links_sports = []\n",
        "for i in range(3):\n",
        "    links_sports += h_links_sports[i]\n",
        "\n",
        "html_links_sports = [lnk for lnk in links_sports if 'stugotz/' in lnk]\n",
        "html_links_sports = ['https://www.happyscribe.com'+i for i in html_links_sports]\n",
        "\n",
        "text_sports = get_episode_text(html_links_sports)\n",
        "#text_sports"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d82c9667",
      "metadata": {
        "id": "d82c9667"
      },
      "source": [
        "Ahora, uno catalogado como de salud y ejercicio, de nombre [The Mindset Mentor](https://www.happyscribe.com/public/the-mindset-mentor):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff8ea2f",
      "metadata": {
        "id": "7ff8ea2f"
      },
      "outputs": [],
      "source": [
        "hf_transcripts = ['https://www.happyscribe.com/public/the-mindset-mentor',\n",
        "                 'https://www.happyscribe.com/public/the-mindset-mentor?page=2',\n",
        "                 'https://www.happyscribe.com/public/the-mindset-mentor?page=3']\n",
        "\n",
        "soup_hf = list(map(get_soup, hf_transcripts))\n",
        "\n",
        "h_links_hf = list(map(get_links, soup_hf))\n",
        "\n",
        "links_hf = []\n",
        "for i in range(3):\n",
        "    links_hf += h_links_hf[i]\n",
        "\n",
        "html_links_hf = [lnk for lnk in links_hf if 'mentor/' in lnk]\n",
        "html_links_hf = ['https://www.happyscribe.com'+i for i in html_links_hf]\n",
        "\n",
        "text_hf = get_episode_text(html_links_hf)\n",
        "#text_hf"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f855c4ae",
      "metadata": {
        "id": "f855c4ae"
      },
      "source": [
        "Otro de los podcasts a utilizar es uno llamado [Stuff You Missed in History Class](https://www.happyscribe.com/public/stuff-you-missed-in-history-class), cuya temática es de historia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ebfa4c2",
      "metadata": {
        "id": "2ebfa4c2"
      },
      "outputs": [],
      "source": [
        "history_transcripts = ['https://www.happyscribe.com/public/stuff-you-missed-in-history-class',\n",
        "                      'https://www.happyscribe.com/public/stuff-you-missed-in-history-class?page=2',\n",
        "                      'https://www.happyscribe.com/public/stuff-you-missed-in-history-class?page=3']\n",
        "\n",
        "soup_history = list(map(get_soup, history_transcripts))\n",
        "\n",
        "h_links_history = list(map(get_links, soup_history))\n",
        "\n",
        "links_history = []\n",
        "for i in range(3):\n",
        "    links_history += h_links_history[i]\n",
        "\n",
        "html_links_history = [lnk for lnk in links_history if 'class/' in lnk]\n",
        "html_links_history = ['https://www.happyscribe.com'+i for i in html_links_history]\n",
        "\n",
        "text_history = get_episode_text(html_links_history)\n",
        "#text_history"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10b697d2",
      "metadata": {
        "id": "10b697d2"
      },
      "source": [
        "Finalmente, el último de los podcasts se llama [My Favorite Murder with Karen Kilgariff and Georgia Hardstark](https://www.happyscribe.com/public/my-favorite-murder-with-karen-kilgariff-and-georgia-hardstark), considerado como de crimen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f15a511",
      "metadata": {
        "id": "3f15a511"
      },
      "outputs": [],
      "source": [
        "crime_transcripts = ['https://www.happyscribe.com/public/my-favorite-murder-with-karen-kilgariff-and-georgia-hardstark',\n",
        "                    'https://www.happyscribe.com/public/my-favorite-murder-with-karen-kilgariff-and-georgia-hardstark?page=2',\n",
        "                    'https://www.happyscribe.com/public/my-favorite-murder-with-karen-kilgariff-and-georgia-hardstark?page=3']\n",
        "\n",
        "soup_crime = list(map(get_soup, crime_transcripts))\n",
        "\n",
        "h_links_crime = list(map(get_links, soup_crime))\n",
        "\n",
        "links_crime = []\n",
        "for i in range(3):\n",
        "    links_crime += h_links_crime[i]\n",
        "\n",
        "html_links_crime = [lnk for lnk in links_crime if 'hardstark/' in lnk]\n",
        "html_links_crime = ['https://www.happyscribe.com'+i for i in html_links_crime]\n",
        "\n",
        "text_crime = get_episode_text(html_links_crime)\n",
        "#text_crime"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a56ac45",
      "metadata": {
        "id": "3a56ac45"
      },
      "source": [
        "Al verificar el número de episodios que contiene cada uno de los podcasts cargados se observa que cada uno contiene 60 episiodios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a71260",
      "metadata": {
        "scrolled": true,
        "id": "a9a71260",
        "outputId": "68626eeb-5272-4813-f9e4-fa5c37c7314b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "60 60 60 60 60\n"
          ]
        }
      ],
      "source": [
        "print(len(text_crime), len(text_science), len(text_history), len(text_hf), len(text_sports))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "396a2642",
      "metadata": {
        "id": "396a2642"
      },
      "source": [
        "Es decir, se trabajará con 300 conjuntos de texto, en principio independientes."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}